{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "098c66f3",
   "metadata": {},
   "source": [
    "## <u>Name</u> : ADVAIT GURUNATH CHAVAN\n",
    "## <u>Contact No.</u> : +91 70214 55852\n",
    "## <u>Mail ID </u> : advaitchavan135@gmail.com\n",
    "## <u>Bharat Intern Task No. </u> : 1 -> Resume Parser\n",
    "### Create an AI to find the correct candidate for the job by using NLTK and some words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11f980e",
   "metadata": {},
   "source": [
    "## Importing the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7806a174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Advait\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Advait\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from nltk import FreqDist\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cd4a60",
   "metadata": {},
   "source": [
    "## Step - 1: Creating a function to Tokenize the text and remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c923544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\")) #selected text language is English\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e4449",
   "metadata": {},
   "source": [
    "## Step - 2: CALCULATING SIMILARITY\n",
    "\n",
    "## Preprocessing: The calculate_similarity function starts by preprocessing the job keywords and the candidate profile. It calls the preprocess_text function to tokenize the text, convert it to lowercase, and remove stopwords. This preprocessing step ensures that we are comparing meaningful and relevant words without noise.\n",
    "\n",
    "## Term frequencies: After preprocessing, the function creates frequency distributions (FreqDist) for both the job keywords and the candidate profile. A frequency distribution is a collection of word frequencies in a given text. It counts the occurrences of each word in the text.\n",
    "\n",
    "## Similarity calculation: Next, the function identifies the common tokens (words) between the job keywords and the candidate profile by finding the intersection of their respective sets of keys (words). It retrieves the tokens that appear in both the job keywords and the candidate profile.\n",
    "\n",
    "## Score calculation: Finally, the function calculates the similarity score by summing the products of the term frequencies for the common tokens. It multiplies the frequency of each common token in the job keywords by its frequency in the candidate profile and accumulates the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8fcd149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(job_keywords, candidate_profile):\n",
    "    # Preprocess the job keywords and candidate profile\n",
    "    job_tokens = preprocess_text(job_keywords)\n",
    "    candidate_tokens = preprocess_text(candidate_profile)\n",
    "\n",
    "    # Calculate term frequencies\n",
    "    job_frequencies = FreqDist(job_tokens)\n",
    "    candidate_frequencies = FreqDist(candidate_tokens)\n",
    "\n",
    "    # Calculate the similarity score\n",
    "    common_tokens = set(job_frequencies.keys()) & set(candidate_frequencies.keys())\n",
    "    score = sum([job_frequencies[token] * candidate_frequencies[token] for token in common_tokens])\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efa1062",
   "metadata": {},
   "source": [
    "## Step -3 : Finding the best candidate\n",
    "\n",
    "## A - Initialization: The find_best_candidate function initializes the variables best_score and best_candidate. These variables will be used to keep track of the highest similarity score and the corresponding best candidate.\n",
    "\n",
    "## B- Iteration: The function iterates through each candidate in the candidate_details list.\n",
    "\n",
    "## C- Similarity calculation: For each candidate, it retrieves the candidate's profile and calculates the similarity score by calling the calculate_similarity function, passing the job_keywords and the candidate_profile as parameters. The calculate_similarity function returns the similarity score between the job keywords and the candidate's profile.\n",
    "\n",
    "## D - Update best candidate: If the calculated score for the current candidate is higher than the current best_score, the best_score variable is updated with the new score, and the best_candidate variable is updated with the name of the current candidate.\n",
    "\n",
    "## E - Return best candidate: After iterating through all the candidates, the function returns the name of the best candidate based on the highest similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1462f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_candidate(job_keywords, candidate_details):\n",
    "    best_score = 0\n",
    "    best_candidate = None\n",
    "\n",
    "    for candidate in candidate_details:\n",
    "        candidate_profile = candidate['profile']\n",
    "        score = calculate_similarity(job_keywords, candidate_profile)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_candidate = candidate['name']\n",
    "\n",
    "    return best_candidate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8c07eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_job_inputs():\n",
    "    job_description = input(\"Enter the job description: \")\n",
    "    num_candidates = int(input(\"\\n\\nEnter the number of candidates: \"))\n",
    "\n",
    "    candidate_details = []\n",
    "    for i in range(num_candidates):\n",
    "        name = input(f\"\\n\\nEnter the name of candidate {i+1}: \")\n",
    "        profile = input(f\"\\n\\nEnter the profile details of candidate {i+1}: \")\n",
    "        candidate_details.append({'name': name, 'profile': profile})\n",
    "\n",
    "    return job_description, candidate_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24bfd4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_candidate_for_job(job_keywords, candidate_details):\n",
    "    best_score = 0\n",
    "    best_candidate = None\n",
    "\n",
    "    for candidate in candidate_details:\n",
    "        candidate_profile = candidate['profile']\n",
    "        score = calculate_similarity(job_keywords, candidate_profile)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_candidate = candidate['name']\n",
    "\n",
    "    return best_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d1064ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the job description: Job Title: AI Software Development Intern Job Description: We are seeking a motivated and skilled AI Software Development Intern to join our software  engineering team. As an AI Software Development Intern, you will have the opportunity to work on  developing and implementing AI-powered software solutions. You will collaborate with experienced  engineers to design and build robust AI systems, leverage machine learning algorithms, and contribute  to the development of cutting-edge AI applications. Responsibilities: 1. Collaborate with the software engineering team to understand project requirements and contribute  to the design and architecture of AI-driven software solutions. 2. Assist in developing and implementing AI models, algorithms, and systems using programming  languages such as Python, Java, or C++. 3. Preprocess and analyze large-scale data sets to extract meaningful insights and prepare them for AI  model training. 4. Train and fine-tune AI models using frameworks like TensorFlow, PyTorch, or scikit-learn, ensuring  optimal performance and accuracy. 5. Integrate AI models into software applications or platforms, considering scalability, performance,  and maintainability. 6. Collaborate with cross-functional teams to develop and improve data pipelines, APIs, and other  software infrastructure components. 7. Write clean, efficient, and well-documented code, following software development best practices  and coding standards. 8. Conduct testing and debugging of AI software components, identifying and resolving software  defects or performance issues. 9. Stay up-to-date with the latest AI technologies, frameworks, and tools, and contribute innovative  ideas for AI-driven software development. 10. Collaborate effectively with team members, participate in code reviews, and actively contribute to  the software development lifecycle. Requirements: 1. Currently pursuing a Bachelor's or Master's degree in Computer Science, Software Engineering, or a  related field. 2. Strong programming skills in languages such as Python, Java, or C++, and familiarity with software  development tools and frameworks. 3. Solid understanding of machine learning algorithms, concepts, and techniques, with practical  experience in applying them. 4. Familiarity with AI libraries and frameworks like TensorFlow, PyTorch, or scikit-learn. 5. Experience with data preprocessing, feature extraction, and data visualization techniques. 6. Knowledge of software development methodologies, version control systems, and agile practices. 7. Strong problem-solving and analytical skills, with the ability to debug and troubleshoot complex  software issues. 8. Excellent written and verbal communication skills, with the ability to work collaboratively in a team  environment. 9. Eagerness to learn and adapt to new technologies and programming languages. 10. Previous software development or internship experience is a plus. This is a paid internship position with flexible working hours. The duration of the internship can be  discussed based on the candidate's availability and the project requirement.\n",
      "\n",
      "\n",
      "Enter the number of candidates: 3\n",
      "\n",
      "\n",
      "Enter the name of candidate 1: David\n",
      "\n",
      "\n",
      "Enter the profile details of candidate 1: David Objective: Highly motivated and talented AI enthusiast seeking an AI Intern position to leverage my skills and  knowledge in artificial intelligence. I am eager to contribute to cutting-edge projects, gain hands-on  experience, and further develop my expertise in machine learning and AI algorithms. Education: Bachelor of Science in Computer Science, XYZ University, City, State (Expected Graduation: May 2024) Relevant Coursework: - Machine Learning - Deep Learning - Data Mining and Analytics - Natural Language Processing - Computer Vision Skills: - Programming Languages: Python, Java, C++ - Machine Learning Frameworks: TensorFlow, PyTorch, scikit-learn - Data Preprocessing and Analysis - Deep Learning Architectures: CNNs, RNNs - Data Visualization Tools: Matplotlib, Plotly - Version Control Systems: Git - Problem-Solving and Critical Thinking - Strong Analytical Skills - Excellent Written and Verbal Communication Projects: 1. AI Chatbot System - Developed an AI-powered chatbot using natural language processing techniques. - Trained a deep learning model using TensorFlow to understand and respond to user queries. - Preprocessed and cleaned the chat data, optimizing its quality and relevance. - Achieved a 90% accuracy rate in classifying and generating appropriate responses. 2. Movie Recommendation System - Built a recommendation system using collaborative filtering and matrix factorization techniques. - Implemented the recommendation algorithm in Python, leveraging scikit-learn and pandas libraries. - Processed and analyzed large datasets to extract user preferences and generate accurate  recommendations. - Improved the user experience and achieved a 20% increase in click-through rates. Experience: AI Research Assistant, ABC Research Lab - Assisted research scientists in conducting experiments and analyzing data for various AI projects. - Contributed to the development and optimization of AI algorithms, particularly in computer vision. - Conducted literature reviews and stayed up-to-date with the latest AI research publications. - Collaborated with team members to document research findings and prepare technical reports. Technical Intern, XYZ Company - Worked on a team responsible for developing an AI-based fraud detection system. - Assisted in the implementation and testing of machine learning models using Python and  TensorFlow. - Conducted data preprocessing and analysis to identify patterns and anomalies in transaction  data. - Collaborated with developers to integrate the AI system into the existing software infrastructure.\n",
      "\n",
      "\n",
      "Enter the name of candidate 2: Alex\n",
      "\n",
      "\n",
      "Enter the profile details of candidate 2: Alex Objective: Highly motivated and passionate AI enthusiast seeking an AI Intern position to contribute to innovative  projects, gain practical experience, and expand my skills in artificial intelligence and machine learning. Education: Bachelor of Science in Computer Science, ABC University, City, State (Expected Graduation: May 2024) Relevant Coursework: - Machine Learning - Deep Learning - Data Mining and Analytics - Natural Language Processing - Computer Vision Skills: - Programming Languages: Python, Java, C++ - Machine Learning Frameworks: TensorFlow, PyTorch, scikit-learn - Data Preprocessing and Analysis - Deep Learning Architectures: CNNs, RNNs - Data Visualization: Matplotlib, Tableau - Version Control Systems: Git - Problem-Solving and Critical Thinking - Strong Analytical Skills - Excellent Written and Verbal Communication Projects: 1. Sentiment Analysis of Social Media Data - Developed a sentiment analysis model using natural language processing techniques. - Preprocessed and cleaned social media data, including feature extraction and sentiment labeling. - Trained a deep learning model using TensorFlow to classify sentiments accurately. - Achieved an 85% accuracy rate in sentiment classification and provided insights into user sentiments. 2. Image Classification using Convolutional Neural Networks - Designed and implemented a deep learning model using a convolutional neural network architecture. - Preprocessed and augmented image datasets to improve model performance and generalization. - Trained the model on a large dataset and achieved a top-5 accuracy of 92% on image classification  tasks. - Conducted extensive experiments to fine-tune hyperparameters and optimize model performance. Experience: AI Research Assistant, XYZ Research Lab - Assisted research scientists in conducting experiments and analyzing data for AI projects. - Developed and implemented machine learning algorithms for data classification and regression tasks. - Collaborated with team members to evaluate and improve existing AI models and algorithms. - Prepared technical reports and presentations to communicate research findings to stakeholders. Software Engineering Intern, DEF Company - Contributed to the development of an AI-powered recommendation system for e-commerce. - Implemented data preprocessing pipelines to clean and transform customer data. - Assisted in training and evaluating machine learning models for personalized product  recommendations. - Collaborated with the engineering team to deploy the recommendation system into  production.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Enter the name of candidate 3: Advait\n",
      "\n",
      "\n",
      "Enter the profile details of candidate 3: ADVAIT CHAVAN +91 70214 55852 Andheri East, Mumbai, Maharashtra, India advaitchavan135@gmail.com CONTACT EDUCATION Anjuman-I-Islam's M.H. Saboo Siddik College of Engineering BACHELOR OF ENGINEERING ELECTRONICS - BE ELECTRONICS Nirmala Memorial College of Commerce and Science Aug 2017 - Mar 2019 HIGHER SECONDARY - SCIENCE HSC SCIENCE MAHARASHRA BOARD 63.54% CGPA till Sem 6- 9.36 out of 10 Aug 2019 - May 2023 SSC MAHARASHTA BOARD Children's Academy May 2016 - Feb 2017 87.20% SKILLS Excellent Problem Analysis Solid Numerical Solving Excel proficiency and knowledge of querying languages Expertise in Data Visualization Great Communication WORK EXPERIENCE Trainity Sept 2022 - Dec 2022 DATA ANALYST INTERN Analyzed data and generated reports using MySQL Workbench 8.0 to identify platform-oriented problems and provide insights for the marketing team and investors, resulting in effective problem\u0002solving. Created a comprehensive HR report on department distribution, facilitating informed recruitment decisions. Operations department accounted for 39% (1843) of the total workforce. Delivered valuable insights to the bank regarding loan approvals, resulting in a healthy financial state with a low NPA ratio of 8% defaulters and 92% non-defaulters. TECH STACK Python Programming PowerBI Tableau Microsoft Excel SQL programming PROJECTS Made a Book Recommendation Engine/System based on Collaborative Book Filtering Technique (CBFT) Gave a detailed analysis on the trends of COVID-19 cases all around the world from Jan 2020 to July 2020 using the bar_chart_race library of python with July 2020 having the most confirmed cases all around the world 362895848 Yoshops Feb 2023 - April 2023 DATA SCIENCE INTERN Developed Python programs to create, import, and format data in Excel files, as well as extract and save mobile numbers from various file formats, demonstrating proficiency in data manipulation and file handling. Conducted exploratory data analysis (EDA) using test data from Yoshops.com sale order file, generating visualizations and reports on customer reviews, payment methods, consumer states and cities, top selling product categories, and more, showcasing analytical skills. Implemented a fake buyer identification system using EDA techniques to identify suspicious orders based on shipping and billing address discrepancies, multiple orders of the same item, unusually large orders, etc., contributing to fraud prevention efforts. Automated validation of products pages, identifying instances where product images were missing on Yoshops.com and other specified categories, creating comprehensive reports in Excel format, demonstrating proficiency in web scraping and data validation. Conducted web scraping and analysis of mobiles and laptops within a budget of Rs. 10,000 on reliance digital.in, providing insights on available products and their specifications, showcasing data collection and analysis skills.\n"
     ]
    }
   ],
   "source": [
    "job_description, candidate_details = take_job_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2b19ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best candidate for the job is: David\n"
     ]
    }
   ],
   "source": [
    "best_candidate = find_best_candidate_for_job(job_description, candidate_details)\n",
    "print(f\"The best candidate for the job is: {best_candidate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc3ec48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
